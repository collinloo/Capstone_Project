{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T01:48:21.757325Z",
     "start_time": "2020-12-25T01:48:20.826420Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_freq_words(df, label, word_no=50, adj=False):\n",
    "    '''\n",
    "    Signature:  get_freq_words(df=None, label=none,word_no=50,adj=False)\n",
    "    Docstring:  Return list of tuple containing words and its frequency.\n",
    "    Parameter:  df: pandas dataframe,\n",
    "                label: int, \n",
    "                word_no: int, total number of most used words to return\n",
    "                adj=boolean\n",
    "    '''\n",
    "    # concat review texts as one string\n",
    "    txt = (df[df['label'] == label]['review']).str.cat(sep= ' ').lower()\n",
    "    # create token from all positive review\n",
    "    doc = nlp(txt)\n",
    "    \n",
    "    # filter out stop-words and punct.\n",
    "    if adj:\n",
    "        words = [token.text for token in doc if token.is_stop != True\n",
    "                 and token.is_punct != True and token.pos_ == 'ADJ']\n",
    "    else:\n",
    "        words = [token.text for token in doc if token.is_stop != True\n",
    "                 and token.is_punct != True]\n",
    "    \n",
    "    # calculate word frequency\n",
    "    word_freq = Counter(words)\n",
    "    common_words = word_freq.most_common(word_no)\n",
    "    return common_words\n",
    "\n",
    "\n",
    "def plot_wcloud(lst, spt1, spt2):\n",
    "    '''\n",
    "    Signature:  plot_wcloud(lst=None, spt1=None, spt2=None)\n",
    "    Docstring:  Return a plotly express figure of word cloud image.\n",
    "    Parameter:  lst: list of tuple of word and count. \n",
    "                spt1: string, subplot one title.\n",
    "                spt2: string, subplot two title.\n",
    "    '''\n",
    "    # create figure with 2 subplot\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        vertical_spacing=0.1,\n",
    "        subplot_titles=(f'Top 50 {spt1} Words',\n",
    "                        f'Top 50 {spt2} Words'))\n",
    "\n",
    "    for i, j  in enumerate(lst):\n",
    "        # create WordCoud object\n",
    "        wc = WordCloud(background_color=\"white\")\n",
    "        # generate word cloud\n",
    "        wc.generate_from_frequencies(dict(j))\n",
    "        \n",
    "        fig.add_trace(go.Image(z=wc),row=i+1, col=1)\n",
    "        \n",
    "    # set subplot title font size\n",
    "    for annotation in fig['layout']['annotations']: \n",
    "        annotation['font']={'size':24}\n",
    "    \n",
    "    fig.update_layout(width=550, height=700, hovermode=False, autosize=False)\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "    fig.show(scale=10)\n",
    "    \n",
    "\n",
    "def eval_model(label, pred, df=None):\n",
    "    '''\n",
    "    Signature:  eval_model(df=None, label=None, pred=None)\n",
    "    Docstring:  Return df containing classification report and plotly figure\n",
    "                , confusion matrix.\n",
    "    Parameter: df: dataframe\n",
    "               label: list/arrary, the label column\n",
    "               pred: list/array, model prediction\n",
    "    '''\n",
    "    # print classificatoin report\n",
    "    display(pd.DataFrame.from_dict(classification_report(\n",
    "        label, pred, output_dict=True)).T)\n",
    "    \n",
    "    # plot confusion matrix\n",
    "    z = np.round(confusion_matrix(label, pred, normalize='true'), 3)\n",
    "    x = ['neg pred', 'pos pred']\n",
    "    y = ['neg actual', 'pos actual']\n",
    "\n",
    "    # set up figure \n",
    "    fig = ff.create_annotated_heatmap(z, x=x, y=y, colorscale='Blues')\n",
    "\n",
    "    # set font size of z values\n",
    "    for i in range(len(fig.layout.annotations)):\n",
    "        fig.layout.annotations[i].font.size = 16\n",
    "\n",
    "    fig.update_layout(title_text='<i><b>Confusion matrix</b></i>',\n",
    "                      height= 500, width=500)\n",
    "\n",
    "    # move xaxis label to bottom\n",
    "    fig.layout.xaxis.update(side='bottom')\n",
    "    # add custom xaxis title\n",
    "    fig.add_annotation(dict(font=dict(color=\"black\",size=16),\n",
    "                        x=0.5,\n",
    "                        y=-.15,\n",
    "                        showarrow=False,\n",
    "                        text=\"Predicted value\",\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\",\n",
    "                       ))\n",
    "\n",
    "    # add custom yaxis title\n",
    "    fig.add_annotation(dict(font=dict(color=\"black\",size=16),\n",
    "                        x=-0.15,\n",
    "                        y=0.5,\n",
    "                        showarrow=False,\n",
    "                        text=\"Actual value\",\n",
    "                        textangle=-90,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"\n",
    "                       ))\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "def rem_stpwrd(txt):\n",
    "    '''\n",
    "    Signature:   rem_stpwrd(txt=None)\n",
    "    Docstring:   Return string with stop words and punct removed\n",
    "    Parameter:   txt: str\n",
    "    '''\n",
    "    doc = nlp(txt.lower())\n",
    "    words = ''\n",
    "    for token in doc:\n",
    "        if token.is_stop != True and token.is_punct != True:\n",
    "            words += token.text + ' '\n",
    "\n",
    "    return words    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
